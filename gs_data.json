{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "4FA6C0AAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Yi Ren (任意)", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=4FA6C0AAAAAJ&citpid=8", "affiliation": "Research Scientist, Bytedance AI Lab", "interests": ["Speech", "Music", "Audio Signal Processing", "Machine Translation"], "email_domain": "@bytedance.com", "homepage": "https://rayeren.github.io/", "citedby": 2178, "publications": {"4FA6C0AAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FastSpeech: Fast, Robust and Controllable Text to Speech", "pub_year": "2019"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:qjMakFHDy7sC", "num_citations": 648, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6010985130650843722", "cites_id": ["6010985130650843722"]}, "4FA6C0AAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FastSpeech 2: Fast and High-Quality End-to-End Text-to-Speech", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:LkGwnXOMwfcC", "num_citations": 585, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13060237915382152145", "cites_id": ["13060237915382152145"]}, "4FA6C0AAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multilingual Neural Machine Translation with Knowledge Distillation", "pub_year": "2019"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:d1gkVwhDpl0C", "num_citations": 187, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5753623392275205285", "cites_id": ["5753623392275205285"]}, "4FA6C0AAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Almost Unsupervised Text to Speech and Automatic Speech Recognition", "pub_year": "2019"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:9yKSN-GCB0IC", "num_citations": 90, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16710802202249302730", "cites_id": ["16710802202249302730"]}, "4FA6C0AAAAAJ:qUcmZB5y_30C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Pseudo Numerical Methods for Diffusion Models on Manifolds", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:qUcmZB5y_30C", "num_citations": 63, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13911281549093893446", "cites_id": ["13911281549093893446"]}, "4FA6C0AAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MultiSpeech: Multi-Speaker Text to Speech with Transformer", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:_FxGoFyzp5QC", "num_citations": 60, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=257446469031533993", "cites_id": ["257446469031533993"]}, "4FA6C0AAAAAJ:3fE2CSJIrl8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PopMAG: Pop Music Accompaniment Generation", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:3fE2CSJIrl8C", "num_citations": 53, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7537456620066024076", "cites_id": ["7537456620066024076"]}, "4FA6C0AAAAAJ:KlAtU1dfN6UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "LRSpeech: Extremely low-resource speech synthesis and recognition", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:KlAtU1dfN6UC", "num_citations": 49, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2976229052422532435", "cites_id": ["2976229052422532435"]}, "4FA6C0AAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Study of Non-autoregressive Model for Sequence Generation", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:hqOjcs7Dif8C", "num_citations": 48, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14794750858649896134", "cites_id": ["14794750858649896134"]}, "4FA6C0AAAAAJ:qxL8FJ1GzNcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Diffsinger: Diffusion acoustic model for singing voice synthesis", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:qxL8FJ1GzNcC", "num_citations": 47, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10338801702241816573,17543750673797975335", "cites_id": ["10338801702241816573", "17543750673797975335"]}, "4FA6C0AAAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SimulSpeech: End-to-End Simultaneous Speech to Text Translation", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:UebtZRa9Y70C", "num_citations": 43, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18282202564539184071", "cites_id": ["18282202564539184071"]}, "4FA6C0AAAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Deepsinger: Singing voice synthesis with data mined from the web", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:kNdYIx-mwKoC", "num_citations": 38, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14039303487459192506", "cites_id": ["14039303487459192506"]}, "4FA6C0AAAAAJ:YOwf2qJgpHMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SongMASS: Automatic Song Writing with Pre-training and Alignment Constraint", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:YOwf2qJgpHMC", "num_citations": 26, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8751829498121461871", "cites_id": ["8751829498121461871"]}, "4FA6C0AAAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "UWSpeech: Speech to Speech Translation for Unwritten Languages", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:Se3iqnhoufwC", "num_citations": 25, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14535875175215134571", "cites_id": ["14535875175215134571"]}, "4FA6C0AAAAAJ:aqlVkmm33-oC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Denoispeech: Denoising text to speech with frame-level noise modeling", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:aqlVkmm33-oC", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16819689550610351819", "cites_id": ["16819689550610351819"]}, "4FA6C0AAAAAJ:Zph67rFs4hoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Task-Level Curriculum Learning for Non-Autoregressive Neural Machine Translation", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:Zph67rFs4hoC", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14167179461331368816", "cites_id": ["14167179461331368816"]}, "4FA6C0AAAAAJ:dhFuZR0502QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PortaSpeech: Portable and High-Quality Generative Text-to-Speech", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:dhFuZR0502QC", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4177501522773357655", "cites_id": ["4177501522773357655"]}, "4FA6C0AAAAAJ:L8Ckcad2t8MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-Singer: Fast Multi-Singer Singing Voice Vocoder With A Large-Scale Corpus", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:L8Ckcad2t8MC", "num_citations": 18, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2358855456085494126", "cites_id": ["2358855456085494126"]}, "4FA6C0AAAAAJ:e5wmG9Sq2KIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:e5wmG9Sq2KIC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2088823687859195371", "cites_id": ["2088823687859195371"]}, "4FA6C0AAAAAJ:Wp0gIr-vW9MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "EMOVIE: A Mandarin Emotion Speech Dataset with a Simple Emotional Text-to-Speech Model", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:Wp0gIr-vW9MC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15315350381922618364", "cites_id": ["15315350381922618364"]}, "4FA6C0AAAAAJ:maZDTaKrznsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Prodiff: Progressive fast diffusion model for high-quality text-to-speech", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:maZDTaKrznsC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9223505264010200019", "cites_id": ["9223505264010200019"]}, "4FA6C0AAAAAJ:4DMP91E08xMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "WSRGlow: A Glow-based Waveform Generative Model for Audio Super-Resolution", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:4DMP91E08xMC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1218606588393750672", "cites_id": ["1218606588393750672"]}, "4FA6C0AAAAAJ:7PzlFSSx8tAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SingGAN: Generative Adversarial Network For High-Fidelity Singing Voice Generation", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:7PzlFSSx8tAC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1698516610881405813", "cites_id": ["1698516610881405813"]}, "4FA6C0AAAAAJ:hFOr9nPyWt4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Revisiting Over-Smoothness in Text to Speech", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:hFOr9nPyWt4C", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11633660030649739510", "cites_id": ["11633660030649739510"]}, "4FA6C0AAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FastLR: Non-Autoregressive Lipreading Model with Integrate-and-Fire", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:8k81kl-MbHgC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9581806397991323587", "cites_id": ["9581806397991323587"]}, "4FA6C0AAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A study of multilingual neural machine translation", "pub_year": "2019"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:W7OEmFMy1HYC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18364568791000482325", "cites_id": ["18364568791000482325"]}, "4FA6C0AAAAAJ:j3f4tGmQtD8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GenerSpeech: Towards Style Transfer for Generalizable Out-Of-Domain Text-to-Speech Synthesis", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:j3f4tGmQtD8C", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14779318166371088188", "cites_id": ["14779318166371088188"]}, "4FA6C0AAAAAJ:iH-uZ7U-co4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:iH-uZ7U-co4C", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15292967138191810315", "cites_id": ["15292967138191810315"]}, "4FA6C0AAAAAJ:hC7cP41nSMkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ProsoSpeech: Enhancing Prosody With Quantized Vector Pre-training in Text-to-Speech", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:hC7cP41nSMkC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=742153645225333053", "cites_id": ["742153645225333053"]}, "4FA6C0AAAAAJ:9ZlFYXVOiuMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FedSpeech: Federated Text-to-Speech with Continual Learning", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:9ZlFYXVOiuMC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15771162422143074501", "cites_id": ["15771162422143074501"]}, "4FA6C0AAAAAJ:blknAaTinKkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Conditional hybrid GAN for melody generation from lyrics", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:blknAaTinKkC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13228305035212945441", "cites_id": ["13228305035212945441"]}, "4FA6C0AAAAAJ:4JMBOYKVnBMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "HiFiDenoise: High-Fidelity Denoising Text to Speech with Adversarial Networks", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:4JMBOYKVnBMC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6731775296221460107", "cites_id": ["6731775296221460107"]}, "4FA6C0AAAAAJ:RHpTSmoSYBkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SyntaSpeech: Syntax-Aware Generative Adversarial Text-to-Speech", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:RHpTSmoSYBkC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12585565410592421516", "cites_id": ["12585565410592421516"]}, "4FA6C0AAAAAJ:TQgYirikUcIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Flow-based Unconstrained Lip to Speech Generation", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:TQgYirikUcIC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12941442660143753050", "cites_id": ["12941442660143753050"]}, "4FA6C0AAAAAJ:k_IJM867U9cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Study of Syntactic Multi-Modality in Non-Autoregressive Machine Translation", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:k_IJM867U9cC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4915893506994619638", "cites_id": ["4915893506994619638"]}, "4FA6C0AAAAAJ:TFP_iSt0sucC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for Text-to-Speech", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:TFP_iSt0sucC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18386504940057315518", "cites_id": ["18386504940057315518"]}, "4FA6C0AAAAAJ:mB3voiENLucC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning the Beauty in Songs: Neural Singing Voice Beautifier", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:mB3voiENLucC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17442799639671484493", "cites_id": ["17442799639671484493"]}, "4FA6C0AAAAAJ:IWHjjKOFINEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MR-SVS: Singing Voice Synthesis with Multi-Reference Encoder", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:IWHjjKOFINEC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18139761552468282156", "cites_id": ["18139761552468282156"]}, "4FA6C0AAAAAJ:NMxIlDl6LWMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GenerSpeech: Towards Style Transfer for Generalizable Out-Of-Domain Text-to-Speech", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:NMxIlDl6LWMC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5881199415670729737", "cites_id": ["5881199415670729737"]}, "4FA6C0AAAAAJ:HDshCWvjkbEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Parallel and High-Fidelity Text-to-Lip Generation", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:HDshCWvjkbEC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1241053409280770066", "cites_id": ["1241053409280770066"]}, "4FA6C0AAAAAJ:J_g5lzvAfSwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:J_g5lzvAfSwC", "num_citations": 0}, "4FA6C0AAAAAJ:NaGl4SEjCO4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:NaGl4SEjCO4C", "num_citations": 0}, "4FA6C0AAAAAJ:RGFaLdJalmkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dance2MIDI: Dance-driven multi-instruments music generation", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:RGFaLdJalmkC", "num_citations": 0}, "4FA6C0AAAAAJ:YFjsv_pBGBYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Diffusion Denoising Process for Perceptron Bias in Out-of-distribution Detection", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:YFjsv_pBGBYC", "num_citations": 0}, "4FA6C0AAAAAJ:BqipwSGYUEgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VarietySound: Timbre-Controllable Video to Sound Generation via Unsupervised Information Disentanglement", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:BqipwSGYUEgC", "num_citations": 0}, "4FA6C0AAAAAJ:hMod-77fHWUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SDMuse: Stochastic Differential Music Editing and Generation via Hybrid Representation", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:hMod-77fHWUC", "num_citations": 0}, "4FA6C0AAAAAJ:JV2RwH3_ST0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Video-Guided Curriculum Learning for Spoken Video Grounding", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:JV2RwH3_ST0C", "num_citations": 0}, "4FA6C0AAAAAJ:M3NEmzRMIkIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "EditSinger: Zero-Shot Text-Based Singing Voice Editing System with Diverse Prosody Modeling", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:M3NEmzRMIkIC", "num_citations": 0}, "4FA6C0AAAAAJ:isC4tDSrTZIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "M4Singer: a Multi-Style, Multi-Singer and Musical Score Provided Mandarin Singing Corpus", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:isC4tDSrTZIC", "num_citations": 0}, "4FA6C0AAAAAJ:mVmsd5A6BfQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "High-Speed and High-Quality Text-to-Lip Generation", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:mVmsd5A6BfQC", "num_citations": 0}, "4FA6C0AAAAAJ:O3NaXMp0MMsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FastDiff 2: Dually Incorporating GANs into Diffusion Models for High-Quality Speech Synthesis"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:O3NaXMp0MMsC", "num_citations": 0}, "4FA6C0AAAAAJ:GnPB-g6toBAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Prosody-TTS: Self-Supervised Prosody Pretraining with Latent Diffusion For Text-to-Speech"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:GnPB-g6toBAC", "num_citations": 0}, "4FA6C0AAAAAJ:_Qo2XoVZTnwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SynCLR: A Synthesis Framework for Contrastive Learning of out-of-domain Speech Representations"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:_Qo2XoVZTnwC", "num_citations": 0}, "4FA6C0AAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SimulS2S: End-to-End Simultaneous Speech to Speech Translation"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:Tyk-4Ss8FVUC", "num_citations": 0}}, "citedby5y": 2175, "hindex": 18, "hindex5y": 18, "i10index": 23, "i10index5y": 23, "cites_per_year": {"2019": 41, "2020": 217, "2021": 661, "2022": 1108, "2023": 120}, "updated": "2023-02-19 08:03:33.273647"}